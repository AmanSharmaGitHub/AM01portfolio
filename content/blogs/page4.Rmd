---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna
  sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa
  sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem
  consequat tincidunt. Vivamus et sagittis tempus.
draft: false
image: GSS.png
keywords: ""
slug: pagefour
title: General Social Survey
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
```

# General Social Survey (GSS)

The [General Social Survey (GSS)](http://www.gss.norc.org/) gathers data on American society in order to monitor and explain trends in attitudes, behaviours, and attributes. Many trends have been tracked for decades, so one can see the evolution of attitudes, etc in American Society.

In this assignment we analyze data from the **2016 GSS sample data**, using it to estimate values of *population parameters* of interest about US adults. The GSS sample data file has 2867 observations of 935 variables, but we are only interested in very few of these variables and you are using a smaller file.


```{r, read_gss_data, cache=TRUE}
gss <- read_csv(here::here("data", "smallgss2016.csv"), 
                na = c("", "Don't know",
                       "No answer", "Not applicable"))

glimpse(gss)
skim(gss)
```

You will also notice that many responses should not be taken into consideration, like "No Answer", "Don't Know", "Not applicable", "Refused to Answer".

We will be creating 95% confidence intervals for population parameters. The variables we have are the following:

- hours and minutes spent on email weekly. The responses to these questions are recorded in the `emailhr` and `emailmin` variables. For example, if the response is 2.50 hours, this would be recorded as emailhr = 2 and emailmin = 30.
- `snapchat`, `instagrm`, `twitter`: whether respondents used these social media in 2016
- `sex`: Female - Male
- `degree`: highest education level attained

```{r}

# Combining the hours and minutes variables 

gss_hrmin <- gss %>%
  mutate(emailhr = as.numeric(emailhr)) %>%
mutate(emailmin = as.numeric(emailmin)) %>%
  mutate_all(funs(replace(.,is.na(.),0))) %>%
   mutate(emailhrmin = (emailhr + (emailmin / 60)))
gss_hrmin
         
# Calculating the confidence interval for the combined variable

formula_emails_ci <- gss_hrmin %>%
  summarise(mean.hrmin = mean(emailhrmin, na.rm = TRUE),
    sd.hrmin = sd(emailhrmin, na.rm = TRUE),
            n.hrmin = n()) %>%
  mutate(se.hrmin = sd.hrmin / sqrt(n.hrmin),
         lower.ci.hrmin = mean.hrmin - qt(1 - (0.05 / 2), n.hrmin - 1) * se.hrmin,
         upper.ci.hrmin = mean.hrmin + qt(1 - (0.05 / 2), n.hrmin - 1) * se.hrmin)

formula_emails_ci



```

```{r}

gss_socialmedia3 <- gss %>%
mutate(snapchat = as.numeric(snapchat)) %>%
mutate(instagrm = as.numeric(instagrm)) %>%
mutate(twitter=as.numeric(twitter))
gss_socialmedia3


gss %>% 
  filter(!snapchat == "NA") %>% 
  dplyr::group_by(sex) %>% 
  count(snapchat) %>% 
  mutate(prop = n/sum(n))

```

We are finding the confidence interval for the difference in proportion of males and females who use social media.

To calculate this we will use the formula for the standard error of the differences in proportions.

```{r}

male_prop_yes <- 0.2172471
male_prop_no <- 1 - male_prop_yes
female_prop_yes <- 0.2340702
female_prop_no <- 1 - female_prop_yes
propdiff <- male_prop_yes - female_prop_yes

sqrt( (male_prop_yes*male_prop_no)/(472+131) + (female_prop_yes*female_prop_no)/(589+180) )

# The standard error is 0.02269678
se_socialmedia <- 0.02269678

# The lower bound:
  CI_lowerbound <- propdiff - 1.96 * se_socialmedia
  CI_upperbound <- propdiff + 1.96 * se_socialmedia

  CI_lowerbound
  CI_upperbound
    
```


## Instagram and Snapchat, by sex

Can we estimate the *population* proportion of Snapchat or Instagram users in 2016?

1. Create a  new variable, `snap_insta` that is *Yes* if the respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), and *No* if not. If the recorded value was NA for both of these questions, the value in your new variable should also be NA.
1. Calculate the proportion of Yes’s for `snap_insta` among those who answered the question, i.e. excluding NAs.
1. Using the CI formula for proportions, please construct 95% CIs for men and women who used either Snapchat or Instagram

```{r}

# Creating the new variables
socialmediausage <- gss %>%
  mutate(snaporinsta = case_when(snapchat == "Yes" & instagrm == "Yes" ~ "Yes", snapchat == "Yes" | instagrm == "Yes" ~ "Yes", snapchat == "No" & instagrm == "No" ~ "No", snapchat == "NA" & instagrm == "NA" ~ "NA" ))

# Calculating the proportions of Yes and those who answered
share_yes <- socialmediausage %>% 
  count(snaporinsta == "Yes") %>% 
  mutate(n/sum(n)*100)

share_yes_no <- socialmediausage %>%
  filter(snaporinsta != "NA")

share_yes_no %>% 
  count(snaporinsta == "Yes") %>% 
  mutate(n/sum(n)*100)

# Social media usage
socialmediastats <- socialmediausage %>%
  group_by(snaporinsta) %>%
  count(snaporinsta) %>%
  pivot_wider(names_from = snaporinsta, values_from = n) %>%
  mutate(proportion_yes = Yes/(Yes+No))

socialmediastats

# 95% confidence interval for social media usage
ci_socmedia <- socialmediausage %>%
  group_by(sex, snaporinsta) %>%
  count(snaporinsta) %>%
  pivot_wider(names_from = snaporinsta, values_from = n) %>%
  mutate(mean = Yes/(Yes+No), se = sqrt(mean*(1-mean)/(Yes+No)), t_critical = qt(0.975, (Yes+No)-1), lower = mean - t_critical*se, upper = mean + t_critical*se)

ci_socmedia

# Raw number of men and women using social media

ci_gender <- socialmediausage %>%
  group_by(sex, snaporinsta) %>%
  count(snaporinsta)

ci_gender1 <- socialmediausage %>%
  group_by(sex, snaporinsta) %>%
  count(snaporinsta) %>%
  pivot_wider(names_from = snaporinsta, values_from = n)

ci_gender1
```

The confidence intervals for men and women do not overlap. We can reject the null hypothesis that these two genders have the same levels of average social media usage, at the 95% significance level.

## Twitter, by education level

Can we estimate the *population* proportion of Twitter users by education level in 2016?. 

There are 5 education levels in variable `degree` which, in ascneding order of years of education, are Lt high school, High School, Junior college, Bachelor, Graduate. 

1. Turn `degree` from a character variable into a factor variable. Make sure the order is the correct one and that levels are not sorted alphabetically which is what R by default does. 
1. Create a  new variable, `bachelor_graduate` that is *Yes* if the respondent has either a `Bachelor` or `Graduate` degree. As before, if the recorded value for either was NA, the value in your new variable should also be NA.
1. Calculate the proportion of `bachelor_graduate` who do (Yes) and who don't (No) use twitter. 
1. Using the CI formula for proportions, please construct two 95% CIs for `bachelor_graduate` vs whether they use (Yes) and don't (No) use twitter. 
1. Do these two Confidence Intervals overlap?

```{r}

# Transforming 'degree' in to a factor variable and non alphabetical
twitter_users <- gss %>%
  group_by(degree) %>%
  count(twitter)
twitter_users

level_order <- c("Lt high school", "High school", "Junior college", "Bachelor", "Graduate")

twitter_count <- gss %>% 
  group_by(degree) %>%
  mutate(degree = factor(degree, levels = level_order))

# Creating new variable bachelor_graduate
twitter_edu <- twitter_count %>%
  mutate(bachelor_graduate = case_when(degree == "Bachelor" | degree == "Graduate" ~ "Yes", degree == "High school" | degree == "Junior college" | degree == "Lt high school" ~ "No", degree == "NA" ~ "NA" ))

# Proportion of bachelor_graduate
twitter_data <- twitter_edu %>%
  group_by(bachelor_graduate, twitter) %>%
  count(bachelor_graduate, twitter) %>%
  filter(bachelor_graduate == "Yes") %>%
  pivot_wider(names_from = twitter, values_from = n) %>%
  mutate(twitter_yes = Yes/(Yes+No))

twitter_data_set <- twitter_edu %>%
  group_by(bachelor_graduate, twitter) %>%
  filter(bachelor_graduate == "Yes", twitter != "NA") %>%
  summarise(count = n()) %>% 
  mutate(per_tw = count/sum(count))

twitter_data_set

# Confidence intervals with 95% of Yes and No, and summary

twitter_CI_yes <- twitter_edu %>%
  group_by(bachelor_graduate, twitter) %>%
  count(bachelor_graduate, twitter) %>%
  pivot_wider(names_from = twitter, values_from = n) %>%
  mutate(mean = Yes/(Yes+No), se = sqrt(mean*(1-mean)/(Yes+No)), t_critical = qt(0.975, (Yes+No)-1), lower = mean - t_critical*se, upper = mean + t_critical*se)

twitter_CI_no <- twitter_edu %>%
  group_by(bachelor_graduate, twitter) %>%
  count(bachelor_graduate, twitter) %>%
  pivot_wider(names_from = twitter, values_from = n) %>%
  mutate(mean = No/(Yes+No), se = sqrt(mean*(1-mean)/(Yes+No)), t_critical = qt(0.975, (Yes+No)-1), lower = mean - t_critical*se, upper = mean + t_critical*se)

twitter_CI_yes

twitter_CI_no

twitter_CI_summary <- twitter_data_set %>%
  summarise(count, per_tw, se = sqrt((per_tw*(1-per_tw)/sum(count))), t_critical = qt(0.975, count-1), margin_of_error = t_critical * se, lower = per_tw - margin_of_error, higher = per_tw + margin_of_error) 

twitter_CI_summary
```

**Overlap?**
We can see the confidence intervals do not overlap. What this means is that we are 95% confident that the population parameters are different from each other.

## Email usage

Can we estimate the *population* parameter on time spent on email weekly?

1. Create a new variable called `email` that combines `emailhr` and `emailmin` to reports the number of minutes the respondents spend on email weekly.
1. Visualise the distribution of this new variable. Find the mean and the median number of minutes respondents spend on email weekly. Is the mean or the median a better measure of the typical amoung of time Americans spend on email weekly? Why?
1. Using the `infer` package, calculate a 95% bootstrap confidence interval for the mean amount of time Americans spend on email weekly. Interpret this interval in context of the data, reporting its endpoints in “humanized” units (e.g. instead of 108 minutes, report 1 hr and 8 minutes). If you get a result that seems a bit odd, discuss why you think this might be the case.
1. Would you expect a 99% confidence interval to be wider or narrower than the interval you calculated above? Explain your reasoning.

```{r}
# Creating email usage variable
email_usage <- gss
  
email_usage[email_usage == "NA"] <- NA 

email_visualise <- email_usage %>% 
  na.omit() %>% 
  mutate(emailmin = as.integer(emailmin),
         emailhr = as.integer(emailhr),
         email = emailmin + emailhr*60)

# Visualizing the distribution of new variable

ggplot(data = email_visualise, aes(x = email)) + geom_boxplot() +
  labs(title = "Email Usage Distribution (Weekly)", x = "Minutes per week", y = "") +
  NULL

ggplot(data = email_visualise, aes(x = email)) + geom_histogram() + labs(title = "Email Usage Distribution (Weekly)", x = "Minutes per week", y = "Number of people") +
NULL
                        
# 95% CI bootstrap for mean time Americans spend on email weekly
library(infer)

email_95 <- email_visualise %>%
  specify(response = email) %>%
  generate (reps = 1000, type = "bootstrap") %>%
  calculate (stat = "mean")

email_95_ci <- email_95 %>%
    get_confidence_interval(level = 0.95, type = "percentile")

email_95_ci

# 99% CI bootstrap for mean time Americans spend on email weekly
email_99 <- email_visualise %>%
  specify(response = email) %>%
  generate (reps = 1000, type = "bootstrap") %>%
  calculate (stat = "mean")

email_99_ci <- email_99 %>%
    get_confidence_interval(level = 0.99, type = "percentile")

email_99_ci

```

**Do we expect the 99% interval to be wider or narrower than the 95%?**
I expect a 99% confidence interval to be wider because the t critical value that we multiply the standard error by would be larger. the 95% confidence interval is a subset of the 99% interval. As we expand the interval, we are 'more sure' that the true population parameter lies in this range.
